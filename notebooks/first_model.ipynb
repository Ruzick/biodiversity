{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "os.chdir('../')\n",
    "\n",
    "from src.features.preprocessing import SoundDS\n",
    "from src.models.model import AudioClassifier\n",
    "from src.models.train_model import training\n",
    "from src.models.predict_model import inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_path</th>\n",
       "      <th>class</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/raw/Poecile_montanus/PoeMon00009.wav</td>\n",
       "      <td>Poecile_montanus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/raw/Poecile_montanus/PoeMon00008.wav</td>\n",
       "      <td>Poecile_montanus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/raw/Poecile_montanus/PoeMon00006.wav</td>\n",
       "      <td>Poecile_montanus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/raw/Poecile_montanus/PoeMon00012.wav</td>\n",
       "      <td>Poecile_montanus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/raw/Poecile_montanus/PoeMon00013.wav</td>\n",
       "      <td>Poecile_montanus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               relative_path             class  class_id\n",
       "0  data/raw/Poecile_montanus/PoeMon00009.wav  Poecile_montanus         0\n",
       "1  data/raw/Poecile_montanus/PoeMon00008.wav  Poecile_montanus         0\n",
       "2  data/raw/Poecile_montanus/PoeMon00006.wav  Poecile_montanus         0\n",
       "3  data/raw/Poecile_montanus/PoeMon00012.wav  Poecile_montanus         0\n",
       "4  data/raw/Poecile_montanus/PoeMon00013.wav  Poecile_montanus         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "files = glob.glob('data/raw/*/*.wav')\n",
    "classes = [re.search('raw/(.+?)/', file).group(1) for file in files]\n",
    "\n",
    "df = pd.DataFrame({'relative_path': files, 'class': classes})\n",
    "codes, uniques = pd.factorize(df['class'])\n",
    "df['class_id'] = codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = df['class_id'].nunique()\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.Subset object at 0x7fb0808d7df0>\n"
     ]
    }
   ],
   "source": [
    "myds = SoundDS(df, data_path='')\n",
    "\n",
    "# Random split of 80:20 between training and validation\n",
    "num_items = len(myds)\n",
    "num_train = round(num_items * 0.8)\n",
    "num_val = num_items - num_train\n",
    "train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
    "\n",
    "print(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7fb0705ce580>\n"
     ]
    }
   ],
   "source": [
    "# Create training and validation data loaders\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=False)\n",
    "\n",
    "print(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model and put it on the GPU if available\n",
    "myModel = AudioClassifier(n_classes=n_classes)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "myModel = myModel.to(device)\n",
    "# Check that it is on Cuda\n",
    "next(myModel.parameters()).device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 4.45, Accuracy: 0.04\n",
      "Epoch: 1, Loss: 4.18, Accuracy: 0.09\n",
      "Epoch: 2, Loss: 3.83, Accuracy: 0.13\n",
      "Epoch: 3, Loss: 3.52, Accuracy: 0.20\n",
      "Epoch: 4, Loss: 3.27, Accuracy: 0.24\n",
      "Epoch: 5, Loss: 3.13, Accuracy: 0.26\n",
      "Epoch: 6, Loss: 3.02, Accuracy: 0.27\n",
      "Epoch: 7, Loss: 2.95, Accuracy: 0.28\n",
      "Epoch: 8, Loss: 2.90, Accuracy: 0.29\n",
      "Epoch: 9, Loss: 2.89, Accuracy: 0.30\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs=10   # Just for demo, adjust this higher.\n",
    "training(myModel, device, train_dl, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.30, Total items: 547\n"
     ]
    }
   ],
   "source": [
    "# Run inference on trained model with the validation set\n",
    "inference(myModel, device, val_dl)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e45715a237ee5589264796642a05a5beb4620493b91758c65ec5d455b603f454"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('4brain_capstone2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
